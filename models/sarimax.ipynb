{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/megan/Thesis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change working directory to the parent directory\n",
    "os.chdir(\"/Users/megan/Thesis\")\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'product_group', 'transaction_count', 'avg_price',\n",
       "       'sales_channel', 'unique_customers', 'unique_articles_sold',\n",
       "       'median_age', 'fashion_news_subscribers', 'first_purchase_days_ago',\n",
       "       'recent_purchase_days_ago', 'age_bin_10-19', 'age_bin_20-29',\n",
       "       'age_bin_30-39', 'age_bin_40-49', 'age_bin_50-59', 'age_bin_60+'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Path to your CSV file\n",
    "csv_path = \"data/top_10_product_groups.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "data = pd.read_csv(csv_path)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing product groups:  20%|██        | 2/10 [00:24<01:39, 12.44s/it]/Users/megan/Thesis/thesis_env/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "Processing product groups:  50%|█████     | 5/10 [02:19<02:44, 32.95s/it]/Users/megan/Thesis/thesis_env/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "Processing product groups: 100%|██████████| 10/10 [05:37<00:00, 33.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing completed. Metrics and plots have been saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modules.utils import process_name\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"final_version/output/1_day/sarimax\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Store results\n",
    "sarimax_results = {}\n",
    "metrics = {}\n",
    "\n",
    "# Iterate over product groups with a progress bar\n",
    "for product_group in tqdm(data['product_group'].unique(), desc=\"Processing product groups\"):\n",
    "    sanitized_group = process_name(product_group)\n",
    "    \n",
    "    # Create output directory for this product group\n",
    "    group_output_dir = os.path.join(output_dir, sanitized_group)\n",
    "    os.makedirs(group_output_dir, exist_ok=True)\n",
    "\n",
    "    # Extract data for the product group\n",
    "    product_data = data[data['product_group'] == product_group]\n",
    "    \n",
    "    # Ensure 'date' is set as index and properly formatted\n",
    "    product_data = product_data.set_index('date')\n",
    "    product_data.index = pd.to_datetime(product_data.index)\n",
    "    product_data = product_data.asfreq('D')\n",
    "\n",
    "    # Fill missing values with zero (adjustable if needed)\n",
    "    product_data = product_data.fillna(0)\n",
    "\n",
    "    # Define endogenous (dependent variable) and exogenous (independent variables)\n",
    "    endog = product_data['transaction_count']\n",
    "    exog = product_data.drop(columns=['transaction_count', 'product_group'], errors='ignore')\n",
    "\n",
    "    # Ensure sufficient data\n",
    "    if len(product_data) < 50:  # Require at least 50 days of data\n",
    "        continue\n",
    "\n",
    "    # Train-test split (80% train, 20% test)\n",
    "    split_idx = int(len(endog) * 0.8)\n",
    "    train_endog, test_endog = endog.iloc[:split_idx], endog.iloc[split_idx:]\n",
    "    train_exog, test_exog = exog.iloc[:split_idx], exog.iloc[split_idx:]\n",
    "\n",
    "    try:\n",
    "        # Train SARIMAX model\n",
    "        model = SARIMAX(\n",
    "            train_endog,\n",
    "            exog=train_exog,\n",
    "            order=(1, 1, 1),\n",
    "            seasonal_order=(1, 1, 1, 7)\n",
    "        )\n",
    "        results = model.fit(disp=False, maxiter=500)\n",
    "\n",
    "        # Generate predictions\n",
    "        pred = results.get_prediction(start=test_endog.index[0], end=test_endog.index[-1], exog=test_exog)\n",
    "        pred_mean = np.maximum(pred.predicted_mean, 0)  # Clip predictions at zero\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        mae = mean_absolute_error(test_endog, pred_mean)\n",
    "        rmse = np.sqrt(mean_squared_error(test_endog, pred_mean))\n",
    "        mape = np.mean(np.abs((test_endog - pred_mean) / np.maximum(test_endog, 1))) * 100\n",
    "        r2 = r2_score(test_endog, pred_mean)\n",
    "\n",
    "        # Store metrics\n",
    "        metrics[product_group] = {\n",
    "            \"MAE\": mae,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAPE\": mape,\n",
    "            \"R2\": r2\n",
    "        }\n",
    "\n",
    "        # Save individual product metrics\n",
    "        metrics_df = pd.DataFrame([metrics[product_group]])\n",
    "        metrics_df.to_csv(os.path.join(group_output_dir, f\"{sanitized_group}_metrics.csv\"), index=False)\n",
    "\n",
    "        # Save trained model\n",
    "        sarimax_results[product_group] = results\n",
    "\n",
    "        # Plot Predicted vs Actual\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(test_endog.index, test_endog, label=\"Actual\", alpha=0.7)\n",
    "        plt.plot(test_endog.index, pred_mean, label=\"Predicted\", alpha=0.7, linestyle='--')\n",
    "        plt.legend()\n",
    "        plt.title(f\"Predicted vs Actual for {product_group}\")\n",
    "        plt.savefig(os.path.join(group_output_dir, f\"{sanitized_group}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # Plot Residuals\n",
    "        residuals = test_endog - pred_mean\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(test_endog.index, residuals, label=\"Residuals\", alpha=0.7)\n",
    "        plt.axhline(0, linestyle='--', color='r', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.title(f\"Residuals for {product_group}\")\n",
    "        plt.savefig(os.path.join(group_output_dir, f\"{sanitized_group}_residuals.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {product_group}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save final metrics summary\n",
    "summary_df = pd.DataFrame.from_dict(metrics, orient=\"index\")\n",
    "summary_df.to_csv(os.path.join(output_dir, \"final_metrics_summary.csv\"))\n",
    "\n",
    "# Compute and save average metrics across all products\n",
    "avg_metrics = {\n",
    "    \"MAE\": np.mean([metrics[pg][\"MAE\"] for pg in metrics]),\n",
    "    \"RMSE\": np.mean([metrics[pg][\"RMSE\"] for pg in metrics]),\n",
    "    \"MAPE\": np.mean([metrics[pg][\"MAPE\"] for pg in metrics]),\n",
    "    \"R2\": np.mean([metrics[pg][\"R2\"] for pg in metrics])\n",
    "}\n",
    "\n",
    "avg_metrics_df = pd.DataFrame([avg_metrics])\n",
    "avg_metrics_df.to_csv(os.path.join(output_dir, \"final_test_avg_metrics.csv\"), index=False)\n",
    "\n",
    "print(\"\\nProcessing completed. Metrics and plots have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing product groups:  20%|██        | 2/10 [00:30<01:58, 14.79s/it]/Users/megan/Thesis/thesis_env/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "Processing product groups:  50%|█████     | 5/10 [01:42<01:52, 22.42s/it]/Users/megan/Thesis/thesis_env/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "Processing product groups: 100%|██████████| 10/10 [04:44<00:00, 28.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processing completed. Metrics and plots have been saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modules.utils import process_name\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"final_version/output/2_weeks/sarimax\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Store results\n",
    "sarimax_results = {}\n",
    "metrics = {}\n",
    "\n",
    "# Forecast horizon\n",
    "forecast_horizon = 14  # 14 days ahead\n",
    "\n",
    "for product_group in tqdm(data['product_group'].unique(), desc=\"Processing product groups\"):\n",
    "    sanitized_group = process_name(product_group)\n",
    "    \n",
    "    # Create output directory for this product group\n",
    "    group_output_dir = os.path.join(output_dir, sanitized_group)\n",
    "    os.makedirs(group_output_dir, exist_ok=True)\n",
    "\n",
    "    # Extract data for the product group\n",
    "    product_data = data[data['product_group'] == product_group]\n",
    "    \n",
    "    # Ensure 'date' is set as index and properly formatted\n",
    "    product_data = product_data.set_index('date')\n",
    "    product_data.index = pd.to_datetime(product_data.index)\n",
    "    product_data = product_data.asfreq('D')\n",
    "\n",
    "    # Fill missing values with zero (adjustable if needed)\n",
    "    product_data = product_data.fillna(0)\n",
    "\n",
    "    # Define endogenous (dependent variable) and exogenous (independent variables)\n",
    "    endog = product_data['transaction_count']\n",
    "    exog = product_data.drop(columns=['transaction_count', 'product_group'], errors='ignore')\n",
    "\n",
    "    # Ensure sufficient data\n",
    "    if len(product_data) < 50 + forecast_horizon:  # Ensure enough data for lookahead\n",
    "        continue\n",
    "\n",
    "    # Train-test split (80% train, 20% test)\n",
    "    split_idx = int(len(endog) * 0.8)\n",
    "    train_endog, test_endog = endog.iloc[:split_idx], endog.iloc[split_idx:]\n",
    "    train_exog, test_exog = exog.iloc[:split_idx], exog.iloc[split_idx:]\n",
    "\n",
    "    try:\n",
    "        # Train SARIMAX model\n",
    "        model = SARIMAX(\n",
    "            train_endog,\n",
    "            exog=train_exog,\n",
    "            order=(1, 1, 1),\n",
    "            seasonal_order=(1, 1, 1, 7)\n",
    "        )\n",
    "        results = model.fit(disp=False, maxiter=500)\n",
    "\n",
    "        # ✅ **Direct 14-Day Forecast Instead of Rolling**\n",
    "        # Extract exogenous data for the next 14 days\n",
    "        exog_forecast = test_exog.iloc[:14] if not test_exog.empty else None\n",
    "        \n",
    "        # Directly predict the next 14 days\n",
    "        pred = results.get_prediction(start=test_endog.index[0], end=test_endog.index[0] + pd.Timedelta(days=13), exog=exog_forecast)\n",
    "        pred_mean = np.maximum(pred.predicted_mean, 0)  # Clip negative values\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        mae = mean_absolute_error(test_endog[:14], pred_mean)\n",
    "        rmse = np.sqrt(mean_squared_error(test_endog[:14], pred_mean))\n",
    "        mape = np.mean(np.abs((test_endog[:14] - pred_mean) / np.maximum(test_endog[:14], 1))) * 100\n",
    "        r2 = r2_score(test_endog[:14], pred_mean)\n",
    "\n",
    "        # Store metrics\n",
    "        metrics[product_group] = {\n",
    "            \"MAE\": mae,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAPE\": mape,\n",
    "            \"R2\": r2\n",
    "        }\n",
    "\n",
    "        # Save individual product metrics\n",
    "        metrics_df = pd.DataFrame([metrics[product_group]])\n",
    "        metrics_df.to_csv(os.path.join(group_output_dir, f\"{sanitized_group}_metrics.csv\"), index=False)\n",
    "\n",
    "        # Save trained model\n",
    "        sarimax_results[product_group] = results\n",
    "\n",
    "        # Plot Predicted vs Actual\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(test_endog.index[:14], test_endog[:14], label=\"Actual\", alpha=0.7)\n",
    "        plt.plot(test_endog.index[:14], pred_mean, label=\"Predicted\", alpha=0.7, linestyle='--')\n",
    "        plt.legend()\n",
    "        plt.title(f\"Predicted vs Actual for {product_group} (14-day ahead)\")\n",
    "        plt.savefig(os.path.join(group_output_dir, f\"{sanitized_group}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # Plot Residuals\n",
    "        residuals = test_endog[:14] - pred_mean\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(test_endog.index[:14], residuals, label=\"Residuals\", alpha=0.7)\n",
    "        plt.axhline(0, linestyle='--', color='r', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.title(f\"Residuals for {product_group} (14-day ahead)\")\n",
    "        plt.savefig(os.path.join(group_output_dir, f\"{sanitized_group}_residuals.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {product_group}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save final metrics summary\n",
    "summary_df = pd.DataFrame.from_dict(metrics, orient=\"index\")\n",
    "summary_df.to_csv(os.path.join(output_dir, \"final_metrics_summary.csv\"))\n",
    "\n",
    "print(\"\\n✅ Processing completed. Metrics and plots have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing completed. Metrics and plots have been saved.\n"
     ]
    }
   ],
   "source": [
    "avg_metrics = {\n",
    "    \"MAE\": np.mean([metrics[pg][\"MAE\"] for pg in metrics]),\n",
    "    \"RMSE\": np.mean([metrics[pg][\"RMSE\"] for pg in metrics]),\n",
    "    \"MAPE\": np.mean([metrics[pg][\"MAPE\"] for pg in metrics]),\n",
    "    \"R2\": np.mean([metrics[pg][\"R2\"] for pg in metrics])\n",
    "}\n",
    "\n",
    "avg_metrics_df = pd.DataFrame([avg_metrics])\n",
    "avg_metrics_df.to_csv(os.path.join(output_dir, \"final_test_avg_metrics.csv\"), index=False)\n",
    "\n",
    "print(\"\\nProcessing completed. Metrics and plots have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
